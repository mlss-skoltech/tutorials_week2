{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "FINAL Point Cloud.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yxd6ML4GDKZa",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "# Learning on Point Clouds\n",
        "\n",
        "This is a tutorial notebook on Learnin on Point Clouds, prepared for the Machine Learning Summer School 2019 (MLSS-2019, http://mlss2019.skoltech.ru) in Moscow, Russia, Skoltech (http://skoltech.ru).\n",
        "\n",
        "Copyright 2019 by Denis Volkhonskiy.\n",
        "\n",
        "![alt text](https://www-cdn.qwertee.io/media/uploads/blog/deep_learning_with_point_clouds/segmented_car.png)\n",
        "\n",
        "## Plan:\n",
        "\n",
        "1. Representation of Point Clouds\n",
        "2. Data Augmentation\n",
        "3. Simple classification network\n",
        "4. Point Net — almost state-of-the-art in classification\n",
        "3. Point Cloud Autoencoder and Generative Learning\n",
        "\n",
        "The purpose of this to torial is to give you an introduction to Deep Learning for Point Clouds. I excpect, that 80% of you will be able to write Point Cloud processing neural network from scratch on PyTorch. After this tutorial, you will also understand some important details of Learning on Point Clouds. You can consider it as a basic knowledge, that will allow you to futher develop your knowledge in this area.\n",
        "\n",
        "\n",
        "## Sources:\n",
        "\n",
        "http://stanford.edu/~rqi/pointnet/\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6B3kMq_YTs1M",
        "colab_type": "text"
      },
      "source": [
        "# Data loading\n",
        "\n",
        "Let us download the data. Just run the cell."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XwS_8uxKjfGa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!wget -O modelnet40-normal_numpy.tar.zip https://box.skoltech.ru/index.php/s/dXgCWvAcYjgd7FC/download\n",
        "!unzip modelnet40-normal_numpy.tar.zip > /dev/null\n",
        "!rm modelnet40-normal_numpy.tar.zip > /dev/null\n",
        "!tar -xvf modelnet40-normal_numpy.tar > /dev/null"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NHUs0Jqr7TZR",
        "colab_type": "text"
      },
      "source": [
        "Now we import all packages that we need"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X7bplBFxlurY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch.utils.data as torch_data\n",
        "import numpy as np\n",
        "\n",
        "from os.path import join\n",
        "from torchvision import transforms\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch\n",
        "\n",
        "from tqdm import tqdm\n",
        "import pandas as pd\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "from IPython import display as ipython_display\n",
        "import pylab as pl\n",
        "from mpl_toolkits.mplot3d import Axes3D\n",
        "\n",
        "%matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6S4pm0ZBSh12",
        "colab_type": "text"
      },
      "source": [
        "Here is some magic for `plotly`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EKy6dKF09pba",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def configure_plotly_browser_state():\n",
        "  import IPython\n",
        "  display(IPython.core.display.HTML('''\n",
        "        <script src=\"/static/components/requirejs/require.js\"></script>\n",
        "        <script>\n",
        "          requirejs.config({\n",
        "            paths: {\n",
        "              base: '/static/base',\n",
        "              plotly: 'https://cdn.plot.ly/plotly-latest.min.js?noext',\n",
        "            },\n",
        "          });\n",
        "        </script>\n",
        "        '''))\n",
        "import IPython\n",
        "\n",
        "IPython.get_ipython().events.register('pre_run_cell', configure_plotly_browser_state)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ASAt9rv-9d51",
        "colab_type": "text"
      },
      "source": [
        "For the current moment we can define PyTorch dataset. All the code here is written for you."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SOwtAcf7MpPW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class ModelNet(torch_data.Dataset):\n",
        "    classes = {\n",
        "        'airplane': 0, 'bathtub': 1, 'bed': 2, 'bench': 3,\n",
        "        'bookshelf': 4, 'bottle': 5, 'bowl': 6, 'car': 7,\n",
        "        'chair': 8, 'cone': 9, 'cup': 10, 'curtain': 11,\n",
        "        'desk': 12, 'door': 13, 'dresser': 14, 'flower_pot': 15,\n",
        "        'glass_box': 16, 'guitar': 17, 'keyboard': 18, 'lamp': 19,\n",
        "        'laptop': 20, 'mantel': 21, 'monitor': 22, 'night_stand': 23,\n",
        "        'person': 24, 'piano': 25, 'plant': 26, 'radio': 27,\n",
        "        'range_hood': 28, 'sink': 29, 'sofa': 30, 'stairs': 31,\n",
        "        'stool': 32, 'table': \n",
        "        33, 'tent': 34, 'toilet': 35,\n",
        "        'tv_stand': 36, 'vase': 37, 'wardrobe': 38, 'xbox': 39\n",
        "    }\n",
        "\n",
        "    def __init__(self, root, mode, n_points=1024, transform=None):\n",
        "        super().__init__()\n",
        "        self.root = root\n",
        "        self.n_points = n_points\n",
        "\n",
        "        self.transform = transform\n",
        "\n",
        "        if mode == 'train':\n",
        "            self.files = np.loadtxt(join(root, 'modelnet40_train.txt'), dtype=str)\n",
        "        else:\n",
        "            self.files = np.loadtxt(join(root, 'modelnet40_test.txt'), dtype=str)\n",
        "\n",
        "        self.choice_idx = [np.random.choice(10000, self.n_points, replace=False) for _ in range(self.__len__())]\n",
        "\n",
        "    def load_npy(self, f, idx):\n",
        "        f = join(self.root, f)\n",
        "        data = np.load(f)\n",
        "\n",
        "        pc = data[:, :3]\n",
        "\n",
        "        pc = pc[self.choice_idx[idx], :]\n",
        "\n",
        "        if self.transform is not None:\n",
        "            pc = self.transform(pc)\n",
        "\n",
        "        return pc\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        f = self.files[idx]\n",
        "        cls = '_'.join(f.split('_')[:-1])\n",
        "\n",
        "        f = '%s/%s.npy' % (cls, f)\n",
        "\n",
        "        pc = self.load_npy(f, idx)\n",
        "\n",
        "        return pc, self.classes[cls]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.files)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YPrlu_DN2dsb",
        "colab_type": "text"
      },
      "source": [
        "Now it is time to use PyTorch Dataloader. It will allow us to iterate "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dl3-GdLwpAHb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_data = ModelNet('./modelnet40-normal_numpy/', mode='train', n_points=2048, transform=None)\n",
        "train_loader = torch_data.DataLoader(train_data, batch_size=64, shuffle=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w2R1HXUDVv2E",
        "colab_type": "text"
      },
      "source": [
        "# Visualization\n",
        "\n",
        "Let us build visualization function\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O0Z5vLHzh7Cn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def plot_3d_point_cloud(x, y, z, show_axis=False, in_u_sphere=False, marker='.', s=8, alpha=.8,\n",
        "                        figsize=(15, 15), elev=10, azim=240, axis=None, title=None, *args, **kwargs):\n",
        "    if axis is None:\n",
        "        fig = plt.figure(figsize=figsize)\n",
        "        ax = fig.add_subplot(111, projection='3d')\n",
        "    else:\n",
        "        ax = axis\n",
        "        fig = axis\n",
        "\n",
        "    if title is not None:\n",
        "        plt.title(title)\n",
        "\n",
        "    sc = ax.scatter(x, y, z, marker=marker, s=s, alpha=alpha, *args, **kwargs)\n",
        "    ax.view_init(elev=azim, azim=azim)\n",
        "\n",
        "    if in_u_sphere:\n",
        "        ax.set_xlim3d(-0.5, 0.5)\n",
        "        ax.set_ylim3d(-0.5, 0.5)\n",
        "        ax.set_zlim3d(-0.5, 0.5)\n",
        "    else:\n",
        "        miv = 0.7 * np.min([np.min(x), np.min(y), np.min(z)])  # Multiply with 0.7 to squeeze free-space.\n",
        "        mav = 0.7 * np.max([np.max(x), np.max(y), np.max(z)])\n",
        "        ax.set_xlim(miv, mav)\n",
        "        ax.set_ylim(miv, mav)\n",
        "        ax.set_zlim(miv, mav)\n",
        "        plt.tight_layout()\n",
        "\n",
        "    if not show_axis:\n",
        "        plt.axis('off')\n",
        "\n",
        "    if 'c' in kwargs:\n",
        "        plt.colorbar(sc)\n",
        "\n",
        "    return fig\n",
        "\n",
        "def plot_two_pc(pc1, pc2, title1='', title2=''):\n",
        "    fig = plt.figure(figsize=(10, 10))\n",
        "\n",
        "    ax = fig.add_subplot(231, projection='3d')\n",
        "    _ = plot_3d_point_cloud(pc1[:, 0], pc1[:, 1], pc1[:, 2], axis=ax, azim=45)\n",
        "    ax.set_title(title1)\n",
        "\n",
        "    ax = fig.add_subplot(232, projection='3d')\n",
        "    _ = plot_3d_point_cloud(pc1[:, 0], pc1[:, 1], pc1[:, 2], axis=ax, azim=90)\n",
        "    ax.set_title(title1)\n",
        "\n",
        "    ax = fig.add_subplot(233, projection='3d')\n",
        "    _ = plot_3d_point_cloud(pc1[:, 0], pc1[:, 1], pc1[:, 2], axis=ax, azim=240)\n",
        "    ax.set_title(title1)\n",
        "\n",
        "    ax = fig.add_subplot(234, projection='3d')\n",
        "    _ = plot_3d_point_cloud(pc2[:, 0], pc2[:, 1], pc2[:, 2], axis=ax, azim=45)\n",
        "    ax.set_title(title2)\n",
        "\n",
        "    ax = fig.add_subplot(235, projection='3d')\n",
        "    _ = plot_3d_point_cloud(pc2[:, 0], pc2[:, 1], pc2[:, 2], axis=ax, azim=90)\n",
        "    ax.set_title(title2)\n",
        "\n",
        "    ax = fig.add_subplot(236, projection='3d')\n",
        "    _ = plot_3d_point_cloud(pc2[:, 0], pc2[:, 1], pc2[:, 2], axis=ax, azim=240)\n",
        "    ax.set_title(title2)\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "def get_plotly_plot(x, y, z, id_of_obj = 0,name = 'chair',mode=False):\n",
        "    init_notebook_mode(mode)\n",
        "   \n",
        "    trace1 = go.Scatter3d(\n",
        "        x=x,\n",
        "        y=y,\n",
        "        z=z,\n",
        "        mode='markers',\n",
        "        marker=dict(\n",
        "            size=4,\n",
        "            line=dict(\n",
        "                color='rgba(217, 217, 217, 0.14)',\n",
        "                width=0.5\n",
        "            ),\n",
        "            opacity=0.8\n",
        "        )\n",
        "    )\n",
        "\n",
        "\n",
        "    data = [trace1]\n",
        "    layout = go.Layout(\n",
        "        margin=dict(\n",
        "            l=0,\n",
        "            r=0,\n",
        "            b=0,\n",
        "            t=0\n",
        "        )\n",
        "    )\n",
        "    fig = go.Figure(data=data, layout=layout)\n",
        "    if mode:\n",
        "        return py.iplot(fig, filename= name)\n",
        "    else:\n",
        "        return iplot(fig, filename= name)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m27moYvz9r82",
        "colab_type": "text"
      },
      "source": [
        "We can visualize two random point cloud using `plotly` library."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LLaDwo4H_NBO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import plotly.plotly as py\n",
        "from plotly.offline import init_notebook_mode, iplot\n",
        "from plotly.graph_objs import Contours, Histogram2dContour, Marker, Scatter\n",
        "import plotly.graph_objs as go\n",
        "\n",
        "sample_pc, _ = next(iter(train_loader))\n",
        "sample_pc = sample_pc.numpy()\n",
        "\n",
        "point_cloud_1, point_cloud_2 = sample_pc[0], sample_pc[1]\n",
        "\n",
        "\n",
        "get_plotly_plot(point_cloud_1[:, 0], point_cloud_1[:, 1], point_cloud_1[:, 2],mode = False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PokgL_mX75tj",
        "colab_type": "text"
      },
      "source": [
        "# Point Cloud problems\n",
        "\n",
        "\n",
        "![alt text](https://raw.githubusercontent.com/charlesq34/pointnet/master/doc/teaser.png)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LJ-XnYVZSI11",
        "colab_type": "text"
      },
      "source": [
        "# Point Cloud Representation\n",
        "\n",
        "Point Cloud is defined as a set of points in 2-dimantional or 3-dimentional space. Since it is a set, each function or neural network we construct should be invariant to permutations of points. \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "![alt text](https://i2.wp.com/www.itzikbs.com/wp-content/uploads/2017/09/PCchallanges_web.png?w=382)\n",
        "\n",
        "However, in memory a point cloud is represented as an array of points. Usually the tensor has shape `[batch_size, n_points, dim]`. That is why it is important to construct functions, that are invariant to permutations:\n",
        "\n",
        "$$\n",
        "f(x_1, x_2, \\ldots, x_n) = f(x_{\\pi_1}, x_{\\pi_2}, \\ldots, x_{\\pi_n})\n",
        "$$\n",
        "\n",
        "where $\\pi$ is a permmutation.\n",
        "\n",
        "For example:\n",
        "\n",
        "$$\n",
        "f(x_1, x_2, \\ldots, x_n) = max  (x_1, x_2, \\ldots, x_n)\n",
        "$$\n",
        "\n",
        "$$\n",
        "f(x_1, x_2, \\ldots, x_n) = sum  (x_1, x_2, \\ldots, x_n)\n",
        "$$\n",
        "\n",
        "\n",
        "![alt text](http://tlgur.com/d/gvx6P5o8)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m9hVM5VoIRtT",
        "colab_type": "text"
      },
      "source": [
        "# Point Clound Data Augmentation\n",
        "\n",
        "Data augmentation is used for enrich your dataset with sligthly modified train sample.\n",
        "\n",
        "For images we use:\n",
        "\n",
        "![alt text](https://www.researchgate.net/publication/319413978/figure/fig2/AS:533727585333249@1504261980375/Data-augmentation-using-semantic-preserving-transformation-for-SBIR.png)\n",
        "\n",
        "Data augmentation for Point Clouds are slightly different. Two commonly used methods are:\n",
        "\n",
        "*   Random rotations\n",
        "\n",
        "$$\n",
        "[x', y', z'] \\leftarrow R(\\theta) [x, y, z]\n",
        "$$\n",
        "\n",
        "*   Random Jittering: $noise \\sim \\mathcal{N}(\\mu, \\sigma)$\n",
        "$$\n",
        "[x', y', z'] \\leftarrow [x, y, z] + noise\n",
        "$$\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Axb5_gUFL6B",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class RandomJitterTransform(object):\n",
        "    def __init__(self, sigma=0.01, clip=0.05):\n",
        "        self.sigma = sigma\n",
        "        self.clip = clip\n",
        "\n",
        "    def __call__(self, data):\n",
        "        \"\"\" Randomly jitter points. jittering is per point.\n",
        "            Input:\n",
        "              Nx3 array, original point clouds\n",
        "            Return:\n",
        "              Nx3 array, jittered point clouds\n",
        "        \"\"\"\n",
        "        N, C = data.shape\n",
        "        assert (self.clip > 0)\n",
        "        jittered_data = np.clip(self.sigma * np.random.randn(N, C), -1 * self.clip, self.clip)\n",
        "        jittered_data += data\n",
        "        return np.float32(jittered_data)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jlf8w56Kibjj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "fig = plt.figure(figsize=(10, 10))\n",
        "\n",
        "ax = fig.add_subplot(121, projection='3d')\n",
        "_ = plot_3d_point_cloud(point_cloud_1[:, 0], point_cloud_1[:, 1], point_cloud_1[:, 2], axis=ax, azim=45)\n",
        "ax.set_title('Original')\n",
        "\n",
        "jitter = RandomJitterTransform()\n",
        "point_cloud_jitter = jitter(point_cloud_1)\n",
        "\n",
        "ax = fig.add_subplot(122, projection='3d')\n",
        "_ = plot_3d_point_cloud(point_cloud_jitter[:, 0], point_cloud_jitter[:, 1], point_cloud_jitter[:, 2], axis=ax, azim=45)\n",
        "ax.set_title('After Jitter')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GavJGUM0FM3d",
        "colab_type": "text"
      },
      "source": [
        "**<font color='red'>TASK: </font>**Now your goal is to implement Random Rotation transformation. Make a random rotation of the input point cloud along ANY direction (or several directions). See code comments for details\n",
        "\n",
        "\n",
        "You can remind rotation matrix here: https://www.wikiwand.com/en/Rotation_matrix#Basic_rotations.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T9IYFmnLIR2T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class RandomRotateTransform(object):\n",
        "    def __init__(self):\n",
        "        pass\n",
        "\n",
        "    def __call__(self, data):\n",
        "        \"\"\" Randomly rotate the point clouds to augument the dataset\n",
        "            rotation is per shape based along ANY direction\n",
        "            Input:\n",
        "              Nx3 array, original point clouds\n",
        "            Return:\n",
        "              Nx3 array, rotated point clouds\n",
        "        \"\"\"\n",
        "\n",
        "        # generate random angle in [0, 2pi]\n",
        "        rotation_angle = np.random.uniform() * 2 * np.pi\n",
        "        ##################################\n",
        "        ##########YOUR CODE HERE##########\n",
        "        ##################################\n",
        "\n",
        "        return np.float32(rotated_data)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ufnTJtHNj5U0",
        "colab_type": "text"
      },
      "source": [
        "Let's check your rotation transformation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D3cbvanHjrU7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "fig = plt.figure(figsize=(10, 10))\n",
        "\n",
        "ax = fig.add_subplot(121, projection='3d')\n",
        "_ = plot_3d_point_cloud(point_cloud_1[:, 0], point_cloud_1[:, 1], point_cloud_1[:, 2], axis=ax, azim=45)\n",
        "ax.set_title('Original')\n",
        "\n",
        "rotation = RandomRotateTransform()\n",
        "point_cloud_rotated = rotation(point_cloud_1)\n",
        "\n",
        "ax = fig.add_subplot(122, projection='3d')\n",
        "_ = plot_3d_point_cloud(point_cloud_rotated[:, 0], point_cloud_rotated[:, 1], point_cloud_rotated[:, 2], axis=ax, azim=45)\n",
        "ax.set_title('After rotation')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E3Y9B59_Ab7v",
        "colab_type": "text"
      },
      "source": [
        "Along with the augmantation transformations we should define Scaling Transformation. It is better to make all points to be in the cube $[0, 1]$."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KkrQXE0MFH7M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class ScaleTransform(object):\n",
        "    def __init__(self):\n",
        "        pass\n",
        "\n",
        "    def __call__(self, data):\n",
        "        data = (data - data.min(axis=0)) / (data.max(axis=0) - data.min(axis=0))\n",
        "        return np.float32(data)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1yK5hx-iAsCR",
        "colab_type": "text"
      },
      "source": [
        "Now we could use all transformations together and obtrain train set and test set:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DPvAGZkb8Ttr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_model_net_40(datadir, batch_size, n_points):\n",
        "    transform = transforms.Compose([\n",
        "        RandomRotateTransform(),\n",
        "        RandomJitterTransform(),\n",
        "        ScaleTransform(),\n",
        "    ])\n",
        "\n",
        "    train_data = ModelNet(datadir, mode='train', n_points=n_points, transform=transform)\n",
        "    test_data = ModelNet(datadir, mode='test', n_points=n_points, transform=transform)\n",
        "\n",
        "    train_loader = torch_data.DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
        "    test_loader = torch_data.DataLoader(test_data, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "    return train_loader, test_loader"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W1hCEObs8ek0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_loader, test_loader = get_model_net_40('./modelnet40-normal_numpy/', batch_size=64, n_points=2048)\n",
        "\n",
        "len(train_loader), len(test_loader)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0q9EMwLLA2_V",
        "colab_type": "text"
      },
      "source": [
        "# Point Cloud Classification\n",
        "\n",
        "Now we will solve the problem of Point Cloud classification on Model Net 40 dataset. Excluding neural network structure, there is no difference between image classification and point cloud classification.\n",
        "\n",
        "In other words, we use well-known ingridients:\n",
        "\n",
        "\n",
        "*   *Batch Stochastic Gradient Descend* optimizer (in our case I use *Adam* algorithm)\n",
        "*   *Cross-Entropy* loss function\n",
        "*   *Accuracy* as the measure of quality\n",
        "\n",
        "\n",
        "Below I define two functions: for training and evaluation."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d0A1BIKk50qJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "def eval_net(net, test_loader, epoch_i):\n",
        "    net = net.eval()\n",
        "\n",
        "    acc = 0\n",
        "    n_pc = 0\n",
        "\n",
        "    for batch_it, (x_tr, y_tr) in enumerate(test_loader):\n",
        "        x_input = torch.FloatTensor(x_tr).cuda()\n",
        "        y_input = torch.LongTensor(y_tr).cuda()\n",
        "\n",
        "        probs = net(x_input)\n",
        "\n",
        "        acc += (probs.data.cpu().argmax(dim=1) == y_tr).sum()\n",
        "        n_pc += y_tr.shape[0]\n",
        "\n",
        "    acc = float(acc.data.cpu().numpy()) / n_pc\n",
        "\n",
        "    print('Test accuracy: %.2f' % acc)\n",
        "\n",
        "def train_net(net, n_epochs, train_loader, test_loader):\n",
        "    loss_func = torch.nn.CrossEntropyLoss()\n",
        "    minimizer = torch.optim.Adam(net.parameters(), lr=0.0001)\n",
        "    \n",
        "    losses = []\n",
        "\n",
        "    for epoch_i in range(10):\n",
        "        print('EPOCH %s' % epoch_i)\n",
        "        with torch.no_grad():\n",
        "          eval_net(net, test_loader, epoch_i)\n",
        "        net = net.train()\n",
        "\n",
        "        acc = 0\n",
        "        n_pc = 0\n",
        "\n",
        "        for batch_it, (x_tr, y_tr) in enumerate(train_loader):\n",
        "            x_input = torch.FloatTensor(x_tr).cuda()\n",
        "            y_input = torch.LongTensor(y_tr).cuda()\n",
        "\n",
        "            probs = net(x_input)\n",
        "\n",
        "            # print(y_input, probs)\n",
        "            loss = loss_func(probs, y_input).mean()\n",
        "\n",
        "            minimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            minimizer.step()\n",
        "\n",
        "            acc += (probs.data.cpu().argmax(dim=1) == y_tr).sum()\n",
        "            n_pc += y_tr.shape[0]\n",
        "\n",
        "            losses.append(loss.item())\n",
        "\n",
        "        ipython_display.display(pl.gcf())\n",
        "        ipython_display.clear_output(wait=True)\n",
        "        plt.title('Loss')\n",
        "        plt.plot(losses)\n",
        "        plt.show()\n",
        "        \n",
        "      "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LGdAqa13LHIc",
        "colab_type": "text"
      },
      "source": [
        "# Simple Point Cloud Network\n",
        "\n",
        "Now it's time to implement your first neural networks for point cloud **classification**. It should be very simple.\n",
        "\n",
        "It basically consists of three steps:\n",
        "\n",
        "1.   Linear layer, that is **applied for each point separately**. Use here `torch.nn.Conv1d`.\n",
        "2.   Get rid of `n_points` dimension. Remember permutation-invariant functions (max, sum)\n",
        "3.   Linear layer \n",
        "\n",
        "You should obtain the following shapes:\n",
        "\n",
        "1.   Input of shape `[batch_size, n_points, 3]`\n",
        "2.   `[batch_size, n_points, 3] -> [batch_size, n_points, 64]`\n",
        "3.   `[batch_size, n_points, 64] -> [batch_size, 64]`\n",
        "4.   `[batch_size, 64] -> [batch_size, num_classes]`\n",
        "\n",
        "\n",
        "Totally there will be $40$ classes.\n",
        "\n",
        "## Linear transformation for each point\n",
        "\n",
        "\n",
        "It is very important to notice how we work with points. Initially we have shape `[batch_size, n_points, 3]` and would like to make it `[batch_size, n_points, 64]`. In other words, we transform our 3-dimentional space into 64-dimantional space. We can do it in two ways:\n",
        "\n",
        "\n",
        "1.   Use `torch.nn.Linear(3, 64)` — standard linear layer;\n",
        "2.   Use `torch.nn.Con1d(3, 64, 1)` — 1d convolution with kernel size $1$, which is equivalent to the Linear layer.\n",
        "\n",
        "\n",
        "The first way with linear layer is OK, but usually it is very inconvinient:\n",
        "\n",
        "\n",
        "\n",
        "*   In order to apply BatchNorm1D to each point, you have to have shape `[batch_size, 3, n_points]`\n",
        "*   I.e. you will need to transpose your tensor before each batch norm and back after it.\n",
        "\n",
        "\n",
        "\n",
        " More convinient will be the following pipeline:\n",
        "\n",
        "1.   Transpose our input tensor once: `[batch_size, n_points, 3] -> [batch_size, 3, n_points]`\n",
        "2.   Apply `torch.nn.Con1d(3, 64, 1)` and obtain shape `[batch_size, 64, n_points]`\n",
        "3.   Apply BatchNorm1d as is along with ReLU.\n",
        "\n",
        "The similarity and difference in `Conv1d` with kernel $1$ and `Linear` layers is described here: https://stackoverflow.com/a/56685503. TLDR: Linear layer is faster, but results are the same. I.e. you can use whatever you want, but for this tutorial Conv1D would be more convenient in terms of implementation.\n",
        "\n",
        "\n",
        "You may need to recall the intefaces of [torch.Tensor.transpose](https://pytorch.org/docs/master/tensors.html#torch.Tensor.transpose), [torch.max](https://pytorch.org/docs/master/torch.html#torch.max), and [torch.sum](https://pytorch.org/docs/master/torch.html#torch.sum). Notice, that `torch.max` returns more than just values.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JZYlTNRsfChJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class SmallNet(nn.Module):\n",
        "    def __init__(self, num_classes=40):\n",
        "        super().__init__()\n",
        "        ##################################\n",
        "        ##########YOUR CODE HERE##########\n",
        "        ##################################\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        ##################################\n",
        "        ##########YOUR CODE HERE##########\n",
        "        ##################################\n",
        "\n",
        "        return x\n",
        "        \n",
        "        "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q0ltvem8pPhd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_net(SmallNet().cuda(), 10, train_loader, test_loader)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c3Jr2NvN2KLZ",
        "colab_type": "text"
      },
      "source": [
        "This is not state-of-the-art, isn't it? Well, let's consider more advanced neural network: Point Net. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EUny3HqrSI8l",
        "colab_type": "text"
      },
      "source": [
        "# Point Net\n",
        "\n",
        "Now we will consider PointNet — a neural network, that was designed for point cloud classification and segmentation problems. Now we work with classification problem, thus you are interested only in blue part of the scheme:\n",
        "\n",
        "![alt text](http://stanford.edu/~rqi/pointnet/images/pointnet.jpg)\n",
        "\n",
        "One can notice, that Point Net is the modification of the networks, that we built in the previous task. It has two main differences:\n",
        "\n",
        "1.   Point Net has more learnable layers\n",
        "2.   It adds so-called T-Net in order to make Point Net invariant to rotations and transformation. \n",
        "\n",
        "Let's take a closer look at T-Net\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SwCijGon1V0v",
        "colab_type": "text"
      },
      "source": [
        "Good feature of Point Net — invariance to rotations. It is done using T-Net. In the original paper it is hard to understand it, but I think it is important. Thus let's drive into details.\n",
        "\n",
        "Consider we have a point cloud $x$ --- matrix of size $2048 \\times 3$. T-Net is a function of x, that returns a matrix of shape $3 \\times 3$. Since all points are located in 3-dimentional space, we can consider the output of T-Net as a transformation matrix and can **multiply** it on $x$:\n",
        "\n",
        "$$\n",
        "x \\leftarrow x \\cdot TNet(x),\n",
        "$$\n",
        "\n",
        "where $\\cdot$ stands for matrix multiplication. Here all cool stuff is hidden:\n",
        "\n",
        "\n",
        "1.   We interpret $TNet(x)$ as a matrix of transformation. I.e. rotation or reflection matrix\n",
        "2.   We predict it depending on the input point cloud $x$\n",
        "3.   We learn the transformation during neural network training.\n",
        "\n",
        "\n",
        "Let us repeat: for the input point cloud $x$ we predict its rotation matrix and apply it.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4ItpkICiDFuO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class TNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.conv1 = torch.nn.Conv1d(3, 64, 1)\n",
        "        self.conv2 = torch.nn.Conv1d(64, 128, 1)\n",
        "        self.conv3 = torch.nn.Conv1d(128, 1024, 1)\n",
        "        self.fc1 = nn.Linear(1024, 512)\n",
        "        self.fc2 = nn.Linear(512, 256)\n",
        "        self.fc3 = nn.Linear(256, 9)\n",
        "        self.relu = nn.ReLU()\n",
        "\n",
        "        self.bn1 = nn.BatchNorm1d(64)\n",
        "        self.bn2 = nn.BatchNorm1d(128)\n",
        "        self.bn3 = nn.BatchNorm1d(1024)\n",
        "        self.bn4 = nn.BatchNorm1d(512)\n",
        "        self.bn5 = nn.BatchNorm1d(256)\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        batchsize = x.size()[0]\n",
        "        x = x.transpose(2, 1)\n",
        "        x = F.relu(self.bn1(self.conv1(x)))\n",
        "        x = F.relu(self.bn2(self.conv2(x)))\n",
        "        x = F.relu(self.bn3(self.conv3(x)))\n",
        "        x = torch.max(x, 2, keepdim=True)[0]\n",
        "        x = x.view(-1, 1024)\n",
        "\n",
        "        x = F.relu(self.bn4(self.fc1(x)))\n",
        "        x = F.relu(self.bn5(self.fc2(x)))\n",
        "        x = self.fc3(x)\n",
        "\n",
        "        iden = torch.from_numpy(np.array([1,0,0,0,1,0,0,0,1]).astype(np.float32)).view(1,9).repeat(batchsize,1)\n",
        "        if x.is_cuda:\n",
        "            iden = iden.cuda()\n",
        "        x = x + iden\n",
        "        x = x.view(-1, 3, 3)\n",
        "        return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "68F9zeDhFcgD",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "Now we are ready to define Point Net. Again, our input will have shape `[batch_size, n_point, 3]`.\n",
        "\n",
        "The structure of the network should be the following:\n",
        "\n",
        "\n",
        "\n",
        "1.   Linear for each point (`torch.nn.Conv1d`)\n",
        "2.   Batch Norm for each point\n",
        "3.   ReLU for each point\n",
        "4.   Linear for each point (`torch.nn.Conv1d`)\n",
        "5.   Batch Norm for each point\n",
        "6.   ReLU for each point\n",
        "7.   Permutation-invariant operation (max, sum)\n",
        "8.   Multy-layer perceptron\n",
        "9.   Output size: `[batch_size, num_classes]`\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zlGeZ8Re9C0I",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class PointNet(nn.Module):\n",
        "    def __init__(self, num_classes=40):\n",
        "        super().__init__()\n",
        "        self.tnet = TNet()\n",
        "        ##################################\n",
        "        ##########YOUR CODE HERE##########\n",
        "        ##################################\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        trans = self.tnet(x)\n",
        "        x = torch.bmm(x, trans)\n",
        "        ##################################\n",
        "        ##########YOUR CODE HERE##########\n",
        "\n",
        "        ##################################\n",
        "\n",
        "        return x\n",
        "        \n",
        "        "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ETXSg0HN9pRM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "net = PointNet().cuda()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jPpv6BIF9jQE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_net(net.cuda(), 10, train_loader, test_loader)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hxLIWtX5Mdf6",
        "colab_type": "text"
      },
      "source": [
        "# Generative Learning\n",
        "\n",
        "In this section we will build an autoencoder for Point Clouds. However, I would like to mention different problems, where you can apply autoencoder and its extentions.\n",
        "\n",
        "\n",
        "## Shape Completion (aka Inpainting)\n",
        "\n",
        "In the shape completion task your goal is to complete the point cloud with missing points. This problem is usually occurs, when the data from LIDAR is not complete.\n",
        "\n",
        "![alt text](https://storage.googleapis.com/groundai-web-prod/media%2Fusers%2Fuser_150793%2Fproject_240441%2Fimages%2Ffigures%2Fkitti_match.png)\n",
        "\n",
        "\n",
        "## Upsampling\n",
        "\n",
        "Another quite important problem is point cloud upsampling. This is very similar to image super-resolution: the goal is to increase the density of your points.\n",
        "\n",
        "![alt text](http://www.pointclouds.org/assets/images/contents/documentation/surface_meshing.png)\n",
        "\n",
        "\n",
        "# Autoencoder\n",
        "\n",
        "Our goal for this section is to build an autoencoder. More formally, for the input point cloud $x$ we want to build an encoder $E$ and decoder $D$ s.t. \n",
        "\n",
        "$$D(E(x)) \\approx x$$\n",
        "\n",
        "Here encoder $E$ and decoder $D$ are neural networks with learnable parameters. \n",
        "\n",
        "![alt text](https://github.com/charlesq34/pointnet-autoencoder/raw/master/doc/teaser.jpg)\n",
        "\n",
        "\n",
        "https://arxiv.org/pdf/1707.02392.pdf\n",
        "\n",
        "\n",
        "## Loss. Chamfer Distance\n",
        "\n",
        "Considering images, usually autoencoder is build with minimization of $l_2$ distance: \n",
        "\n",
        "$$\n",
        "\\parallel D(E(x)) - x \\parallel^2_2 \\to \\min\n",
        "$$\n",
        "\n",
        "This is OK for images. But this is completely not OK for point clouds. Remember, that point cloud is a set. In other words, we can permute points, and it will be the same set of points. \n",
        "\n",
        "Thus we need a function of two sets, that will represent, how close are they. Usually, people use Chamfer Distance or Earth mover's distance. We will consider Chamfer Distance (CD):\n",
        "\n",
        "$$\n",
        "CD(S_1, S_2) = \\sum_{x\\in S_1} \\min_{y\\in S_2} \\parallel x-y \\parallel_2^2 + \\sum_{y\\in S_2} \\min_{x\\in S_1} \\parallel x-y \\parallel_2^2\n",
        "$$\n",
        "\n",
        "Intuitively, we do the following. For each point in the first set, we find the closest point in the second set and compute a distance between them. Then we sum up these distances. Then we do the same, swapping sets (i.e. compute distances from points from the second set to the first one). Finaly, we sum up every distance."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mEuAmbAj6yBD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class ChamferDistance(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        pass\n",
        "\n",
        "    def pairwise_dist(self, x, y):\n",
        "        xx, yy, zz = torch.mm(x, x.t()), torch.mm(y, y.t()), torch.mm(x, y.t())\n",
        "        rx = (xx.diag().unsqueeze(0).expand_as(xx))\n",
        "        ry = (yy.diag().unsqueeze(0).expand_as(yy))\n",
        "        P = (rx.t() + ry - 2 * zz)\n",
        "        return P\n",
        "\n",
        "    def batch_pairwise_dist(self, a, b):\n",
        "        x, y = a, b\n",
        "        bs, num_points, points_dim = x.size()\n",
        "        xx = torch.bmm(x, x.transpose(2, 1))\n",
        "        yy = torch.bmm(y, y.transpose(2, 1))\n",
        "        zz = torch.bmm(x, y.transpose(2, 1))\n",
        "        diag_ind = torch.arange(0, num_points).type(torch.cuda.LongTensor)\n",
        "\n",
        "        rx = xx[:, diag_ind, diag_ind].unsqueeze(1).expand_as(xx)\n",
        "        ry = yy[:, diag_ind, diag_ind].unsqueeze(1).expand_as(yy)\n",
        "        P = (rx.transpose(2, 1) + ry - 2 * zz)\n",
        "        return P\n",
        "\n",
        "    def forward(self, input, target):\n",
        "        dist = self.batch_pairwise_dist(input, target)\n",
        "\n",
        "        values_1, indices = dist.min(dim=1)\n",
        "        values_2, indices = dist.min(dim=2)\n",
        "\n",
        "        return torch.sum(values_1, dim=1) + torch.sum(values_2, dim=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mcsRHF6JxA08",
        "colab_type": "text"
      },
      "source": [
        "Now our goal is to construct two neural networks: encoder and decoder. I propose you the following.\n",
        "\n",
        "\n",
        "1.   Your Encoder should be like a Point Net. It should:\n",
        "          a. Be invariant to the number of input points\n",
        "          b. Be invariant to the permutation among points\n",
        "          c. Have botteneck size 1024\n",
        "2.   Your Decoder Should obtain a vector of size 1024 and transform it into a set of points, i.e. matrix with shape `[batch_size, n_point, n_dim]`\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1dUH8paYMdqV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Encoder(nn.Module):\n",
        "    def __init__(self, bottleneck_size):\n",
        "        super().__init__()\n",
        "        self.bottleneck_size = bottleneck_size\n",
        "        ##################################\n",
        "        ##########YOUR CODE HERE##########\n",
        "        ##################################\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        ##################################\n",
        "        ##########YOUR CODE HERE##########\n",
        "        ##################################\n",
        "        x, max_idx = torch.max(x, 2)\n",
        "        x = x.view(-1, self.bottleneck_size)\n",
        "        \n",
        "        return x, max_idx\n",
        "\n",
        "class Decoder(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        ##################################\n",
        "        ##########YOUR CODE HERE##########\n",
        "        ##################################\n",
        "\n",
        "    def forward(self, x):\n",
        "        ##################################\n",
        "        ##########YOUR CODE HERE##########\n",
        "        ##################################\n",
        "        return x\n",
        "        \n",
        "        "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "itEJ8I_oMd1u",
        "colab_type": "text"
      },
      "source": [
        "We again have two function for training and evaluations of our networks."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VT1Yu6huMd9q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "def eval_ae(enc, dec, test_loader, epoch_i):\n",
        "    enc, dec = enc.train(), dec.train()\n",
        "    loss_func = ChamferDistance()\n",
        "\n",
        "    loss = 0\n",
        "    n_pc = 0\n",
        "\n",
        "    for batch_it, (x_tr, y_tr) in enumerate(test_loader):\n",
        "        x_input = torch.FloatTensor(x_tr).cuda()\n",
        "        y_input = torch.LongTensor(y_tr).cuda()\n",
        "\n",
        "        out = dec(enc(x_input)[0])\n",
        "        \n",
        "        loss += loss_func(out, x_input).sum()\n",
        "        n_pc += y_tr.shape[0]\n",
        "\n",
        "    cd = float(loss.data.cpu().numpy()) / n_pc\n",
        "\n",
        "    print('Test CD: %.2f' % cd)\n",
        "\n",
        "    plot_two_pc(x_tr.numpy()[0], out.detach().cpu().numpy()[0], 'Original', 'Predicted')\n",
        "\n",
        "def train_ae(enc, dec, n_epochs, train_loader, test_loader):\n",
        "    loss_func = ChamferDistance()\n",
        "    minimizer = torch.optim.Adam(list(enc.parameters()) + list(dec.parameters()), lr=0.0001)\n",
        "    \n",
        "    losses = []\n",
        "\n",
        "    for epoch_i in range(10):\n",
        "        print('EPOCH %s' % epoch_i)\n",
        "\n",
        "        with torch.no_grad():\n",
        "          eval_ae(enc, dec, test_loader, epoch_i)\n",
        "        enc, dec = enc.train(), dec.train()\n",
        "\n",
        "\n",
        "        for batch_it, (x_tr, y_tr) in enumerate(train_loader):\n",
        "            x_input = torch.FloatTensor(x_tr).cuda()\n",
        "            y_input = torch.LongTensor(y_tr).cuda()\n",
        "\n",
        "            out = dec(enc(x_input)[0])\n",
        "\n",
        "            loss = loss_func(x_input, out).mean()\n",
        "\n",
        "            minimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            minimizer.step()\n",
        "\n",
        "            losses.append(loss.item())\n",
        "\n",
        "        ipython_display.display(pl.gcf())\n",
        "        ipython_display.clear_output(wait=True)\n",
        "\n",
        "        plt.title('Loss')\n",
        "        print(losses)\n",
        "        plt.plot(losses)\n",
        "        plt.show()\n",
        "        \n",
        "      "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TiXI0Im3Dgk0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "enc = Encoder(bottleneck_size=1024).cuda()\n",
        "dec = Decoder().cuda()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QceTz4_sD7Dg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_ae(enc, dec, 10, train_loader, test_loader)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kGg8xSk3Yx_J",
        "colab_type": "text"
      },
      "source": [
        "Now it's time to play with nice visualization. In our encoder network there is `torch.max` function, which allow us to get rid of `n_points` dimension.\n",
        "\n",
        "Note, that not all points will play their role for the result of max function (in case of all features will be very small). Points that are important for max function, are called *critical set*. Let us visualize it."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ih3pg8telra0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sample_pc, _ = next(iter(test_loader))\n",
        "\n",
        "with torch.no_grad():\n",
        "  _, max_idx = enc(sample_pc.cuda())\n",
        "  max_idx = max_idx.cpu().numpy()\n",
        "\n",
        "points_idxs = np.unique(max_idx[0])\n",
        "plot_two_pc(sample_pc.numpy()[0], sample_pc.numpy()[0, points_idxs], 'Original', 'Critical Set')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iickqurV8sd7",
        "colab_type": "text"
      },
      "source": [
        "Visualization from Point Net paper:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FuJhj6GlbLbh",
        "colab_type": "text"
      },
      "source": [
        "![alt text](http://stanford.edu/~rqi/pointnet/images/kp_ss_visu1.jpg)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sx4YKgT8Z-o1",
        "colab_type": "text"
      },
      "source": [
        "Hope it was very useful. In case of questions feel free to contact me. \n",
        "\n",
        "\n",
        "*   Denis Volkhonskiy\n",
        "*   Telegram: http://teleg.run/dvolkhonskiy\n",
        "*   Email: dvolkhonskiy@gmail.com\n",
        "\n",
        "\n"
      ]
    }
  ]
}